{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing ATARI-ram games using python-neat and convolutional autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import wrappers\n",
    "from __future__ import print_function\n",
    "import os\n",
    "%matplotlib inline\n",
    "import neat\n",
    "import visualize\n",
    "os.environ['DISPLAY']=':0'\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "import gym\n",
    "import numpy as np\n",
    "import json\n",
    "from object_detection import *\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "import multiprocessing\n",
    "from multiprocessing.reduction import reduce_connection\n",
    "from hashlib import sha256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_config_filename = 'fc.config'\n",
    "game_name = 'Skiing'\n",
    "game_version = 'v0'\n",
    "game = game_name + '-' + game_version\n",
    "num_evaluations = 2\n",
    "num_cores = 11\n",
    "population_size = 80\n",
    "encoder_filename = './data/{}_Encoder_08_02'.format(game_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-09 14:39:26,274] Making new env: Skiing-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection features (frame -> lowres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit detector and save\n",
    "#odf = ObjectDetectionFeatures2(env)\n",
    "odf_filename = 'odf-' + game + '.config'\n",
    "#pickle.dump(odf, open(odf_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load detector\n",
    "odf = pickle.load(open(odf_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform for detector\n",
    "output_shape = (60, 60)\n",
    "#process_image = lambda x: (resize(odf.get_simple_image(x), output_shape, order=0) * 255).astype('uint8')\n",
    "process_image = lambda x: (np.random.rand(60,60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create neat-python population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load configuration.\n",
    "config_initial = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                             neat.DefaultSpeciesSet, neat.DefaultStagnation, fc_config_filename)\n",
    "\n",
    "config_initial.genome_config.num_inputs = 64 #env.observation_space.shape[0]\n",
    "config_initial.genome_config.num_outputs = env.action_space.n\n",
    "config_initial.pop_size = population_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "game_fc_config_filename = 'fc-' + game + '.config'\n",
    "\n",
    "config_initial.save(game_fc_config_filename)\n",
    "\n",
    "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation, game_fc_config_filename)\n",
    "\n",
    "# Create the population, which is the top-level object for a NEAT run.\n",
    "p = neat.Population(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add reporters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a stdout reporter to show progress in the terminal.\n",
    "p.add_reporter(neat.StdOutReporter())\n",
    "stats = neat.StatisticsReporter()\n",
    "p.add_reporter(stats)\n",
    "p.add_reporter(neat.Checkpointer(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff for pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compress_pipe(p):\n",
    "    pp = pickle.dumps(reduce_connection(p))\n",
    "    return(pp)\n",
    "def decompress_pipe(pp):\n",
    "    upw = pickle.loads(pp)\n",
    "    pp = upw[0](upw[1][0],upw[1][1],upw[1][2])\n",
    "    return(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spawn cuda conv autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cuda_process_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dc890e6aa8ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcuda_process_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcuda_process_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cuda_process_p' is not defined"
     ]
    }
   ],
   "source": [
    "cuda_process_p.terminate()\n",
    "cuda_process_p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing keras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "m = multiprocessing.Manager()\n",
    "cuda_q = m.Queue()\n",
    "\n",
    "def cuda_process():\n",
    "    print(\"Importing keras...\")\n",
    "    import os    \n",
    "    os.environ['THEANO_FLAGS'] = \"device=gpu1\"\n",
    "    from keras.models import model_from_json\n",
    "    from keras import backend as K\n",
    "    K.set_image_dim_ordering('th')\n",
    "    \n",
    "    print(\"Loading GPU encoder...\")\n",
    "    \n",
    "    with open(encoder_filename + '.txt', 'r') as model_file:\n",
    "        gpu_encoder = model_from_json(json.loads(next(model_file)))\n",
    "\n",
    "    gpu_encoder.load_weights(encoder_filename + '.h5')\n",
    "    \n",
    "    print(\"Listening\")\n",
    "    global cuda_q\n",
    "    while True:\n",
    "        [buf, p] = cuda_q.get(block = True)\n",
    "        #print(\"processing cuda...\")\n",
    "        try:\n",
    "            features = gpu_encoder.predict(np.array([buf]))[0]\n",
    "        except:\n",
    "            print(\"Error encoding\")\n",
    "            features = np.zeros(64)\n",
    "        p = decompress_pipe(p)\n",
    "        p.send(features)\n",
    "        \n",
    "cuda_process_p = multiprocessing.Process(target = cuda_process, args = ())\n",
    "cuda_process_p.daemon = True\n",
    "cuda_process_p.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open CPU encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CPU encoder...\n"
     ]
    }
   ],
   "source": [
    "os.environ['THEANO_FLAGS'] = \"device=cpu\"\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "print(\"Loading CPU encoder...\")\n",
    "\n",
    "with open(encoder_filename + '.txt', 'r') as model_file:\n",
    "    cpu_encoder = model_from_json(json.loads(next(model_file)))\n",
    "\n",
    "cpu_encoder.load_weights(encoder_filename + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define fitness via game score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buf = []\n",
    "use_gpu = False\n",
    "\n",
    "def get_features_cpu(buf):\n",
    "    return(cpu_encoder.predict(np.array([buf]))[0])\n",
    "\n",
    "def get_features_gpu(buf):\n",
    "    global cuda_q\n",
    "    a, b = multiprocessing.Pipe()\n",
    "    b = compress_pipe(b)\n",
    "    cuda_q.put([buf, b])\n",
    "    features = a.recv()\n",
    "    return(features)\n",
    "\n",
    "def get_features(buf):\n",
    "    #global use_gpu\n",
    "    \n",
    "    s = np.random.rand(1)[0]\n",
    "    use_gpu = (s > 0.3)\n",
    "    \n",
    "    if use_gpu:\n",
    "        return(get_features_gpu(buf))\n",
    "    return(get_features_cpu(buf))\n",
    "\n",
    "def transform_observation(observation):\n",
    "    global buf\n",
    "\n",
    "    image = process_image(env.ale.getScreenGrayscale()[:, :, 0])\n",
    "    if len(buf) < 3:\n",
    "        buf.append(image)\n",
    "        buf.append(image)\n",
    "        buf.append(image)\n",
    "    else:\n",
    "        buf.pop(0)\n",
    "        buf.append(image)\n",
    "\n",
    "    features = get_features(buf)\n",
    "    return features\n",
    "\n",
    "# a = argmax_a Q(s,a)\n",
    "def predict_action(observation, network):\n",
    "    observation = transform_observation(observation)\n",
    "    output = network.activate(observation)\n",
    "    action = np.argmax(output)\n",
    "    return(action)\n",
    "\n",
    "# play num_evaluations games, take mean\n",
    "def evaluate_network(env, network):\n",
    "    rewards = []\n",
    "    i = 0\n",
    "    while i < num_evaluations:\n",
    "        rewards += [get_reward(env, network)]\n",
    "        i += 1\n",
    "\n",
    "    res = np.array(rewards).mean()\n",
    "    return res\n",
    "\n",
    "# play 1 game with network\n",
    "def get_reward(env, network):\n",
    "    global buf\n",
    "    buf = []\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    iteration, total_reward = 0, 0\n",
    "        \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = predict_action(observation, network)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        #if iteration % 500 == 0:\n",
    "        #    print(str(iteration))\n",
    "\n",
    "        if total_reward < -12000 or iteration >= 8000:\n",
    "            break\n",
    "\n",
    "        iteration += 1\n",
    "        \n",
    "    return total_reward\n",
    "\n",
    "def evaluate_genome(genome, config):\n",
    "    # updating randomstate\n",
    "    h = sha256(genome.__str__())\n",
    "    seed = np.frombuffer(h.digest(), dtype='uint32')\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    \n",
    "    network = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    fitness = evaluate_network(env, network)\n",
    "    return fitness\n",
    "\n",
    "evaluator = neat.parallel.ParallelEvaluator(num_workers = num_cores, eval_function = evaluate_genome, timeout = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit -n1 print(evaluate_genome(p.species.get_species(1).members[1], config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ****** Running generation 4 ****** \n",
      "\n",
      "Population's average fitness: -9511.40000 stdev: 1114.45630\n",
      "Best fitness: -9013.00000 - size: (3, 186) - species 1 - id 128\n",
      "Species length: 1 totaling 30 individuals\n",
      "Species no improv: {1: 2}\n",
      "Average adjusted fitness: 0.833\n",
      "Spawn amounts: [30]\n",
      "Species fitness  : [0.83336676696756951]\n",
      "Mean genetic distance 1.20414163283, std dev 0.247341803784\n",
      "Total extinctions: 0\n",
      "Generation time: 204.250 sec (233.672 average)\n"
     ]
    }
   ],
   "source": [
    "# Run evolution\n",
    "winner = p.run(evaluator.evaluate, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "winner = p.run(evaluator.evaluate, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the winning genome.\n",
    "#print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "\n",
    "# Show output of the most fit genome against training data.\n",
    "winner_network = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "visualize.draw_net(config, winner, False)\n",
    "visualize.plot_stats(stats, ylog = False, view = False)\n",
    "visualize.plot_species(stats, view = False)\n",
    "\n",
    "#p = neat.Checkpointer.restore_checkpoint('neat-checkpoint-4')\n",
    "#p.run(eval_genomes, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate from checkpoint & send to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = neat.Checkpointer.restore_checkpoint('neat-checkpoint-1244')\n",
    "p.run(evaluator.evaluate, 1)\n",
    "winner = p.best_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_eval = gym.make(game)\n",
    "monitor_path = '/tmp/' + game + '-eval'\n",
    "env_eval = wrappers.Monitor(env_eval, monitor_path)\n",
    "def evaluate_with_video(game, network):\n",
    "    for i_episode in range(100):\n",
    "        observation = env_eval.reset()\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        while True:\n",
    "            env_eval.render()\n",
    "            action = predict_action(observation, network)\n",
    "            observation, reward, done, info = env_eval.step(action)\n",
    "            total_reward += reward\n",
    "            t += 1\n",
    "            if done:\n",
    "                print(\"Episode finished after {0} timesteps reward = {1}\".format(t+1, total_reward))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_with_video(game, winner_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env_eval.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gym.upload(monitor_path, api_key='sk_ciz2F0csRzCkpESayoRuug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 92.2502232408\n"
     ]
    }
   ],
   "source": [
    "# FPS total\n",
    "t_initial = time()\n",
    "env.reset()\n",
    "F = 100\n",
    "buf = []\n",
    "for i in range(F):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    features = transform_observation(1)\n",
    "t_end = time()\n",
    "print(\"FPS: \" + str(1. * F / (t_end - t_initial)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 178.771620251\n"
     ]
    }
   ],
   "source": [
    "# FPS emulator-only\n",
    "t_initial = time()\n",
    "env.reset()\n",
    "F = 100\n",
    "buf = []\n",
    "for i in range(F):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "t_end = time()\n",
    "print(\"FPS: \" + str(1. * F / (t_end - t_initial)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 165.642134662\n"
     ]
    }
   ],
   "source": [
    "# FPS OD-only\n",
    "t_initial = time()\n",
    "env.reset()\n",
    "F = 100\n",
    "buf = []\n",
    "for i in range(F):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    image = process_image(env.ale.getScreenGrayscale()[:, :, 0])\n",
    "    buf = [image,image,image]\n",
    "t_end = time()\n",
    "print(\"FPS: \" + str(1. * F / (t_end - t_initial)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    get_features_gpu(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features_gpu(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.83 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit get_features_gpu(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 27 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit get_features_cpu(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
