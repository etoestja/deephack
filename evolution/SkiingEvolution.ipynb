{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skiing by evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skiing game has a reward which is more difficult in terms of learning.\n",
    "\n",
    "The goal of the game is to avoid trees and pass through the gates, but the reward is given only at the end. Reward equals to -3..-7 for living and -500 * (missed gates) at the end.\n",
    "\n",
    "Because of that, the agent can evaluate its behavior only at the end of the game, and not immediately after passing (or not passing) gates.\n",
    "\n",
    "The standart Q-learning technique would require significant amount of training in this case, because 99.9% of the network's weight updates would be meaningless, as they correspond to that random living penalty.\n",
    "\n",
    "Therefore, we use another approach to train the network: an evolutionary algorithm. We use mutation and selection based on sum of rewards to train the network, instead of gradient updates. The solution basically follows this scheme:\n",
    "1. Create random set of NN's, each consisting of 2 convolutional and 2 fully-connected layers\n",
    "2. Evaluate their fitness (i.e. sum of rewards)\n",
    "3. Choose the best ones\n",
    "4. Crossover and mutate them (possibly adding new neurons)\n",
    "5. Repeat stage 2 for the result.\n",
    "\n",
    "Our solution is inspired by a method called NEAT, used to play Mario: https://www.youtube.com/watch?v=qv6UVOQ0F44\n",
    "\n",
    "The example on the video uses handcrafted features, but we use 2 convolutional layers trained the same way instead. This way, this approach (theoretically) can play any game of this kind, without any game-specific features or rewards\n",
    "\n",
    "However, training was not enough, so now it is able only of going straight down (at the beginning it presses keys quite randomly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "import theano\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resizing to black-white 42x42\n",
    "def _process_frame42(frame):\n",
    "    frame = frame[34:34+160, :160]\n",
    "    # Resize by half, then down to 42x42 (essentially mipmapping). If\n",
    "    # we resize directly we lose pixels that, when mapped to 42x42,\n",
    "    # aren't close enough to the pixel boundary.\n",
    "    frame = cv2.resize(frame, (80, 80))\n",
    "    frame = cv2.resize(frame, (42, 42))\n",
    "    frame = frame.mean(2)\n",
    "    frame = frame.astype(np.float32)\n",
    "    frame *= (1.0 / 255.0)\n",
    "    frame = np.reshape(frame, [42, 42, 1])\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neural Evolution\n",
    "class NeuralNetwork:\n",
    "    conv1_size = 5\n",
    "    conv2_size = 5\n",
    "    evolution_probability = 0.97\n",
    "    scale_factor = 1\n",
    "    def __init__(self):\n",
    "        self.conv1_filtr = np.random.standard_normal((self.conv1_size, self.conv1_size))\n",
    "        self.conv2_filtr = np.random.standard_normal((self.conv2_size, self.conv2_size))\n",
    "        self.dense1_weights = np.random.standard_normal((49, 100))\n",
    "        self.dense2_weights = np.random.standard_normal((100, 3))\n",
    "    def Convolve(self, compressed_observation):\n",
    "        input_var = T.dmatrix('inputs')\n",
    "\n",
    "        pooling = theano.function([input_var],\n",
    "                                  theano.tensor.signal.pool.pool_2d(input_var, (2, 2), ignore_border=True))\n",
    "        return pooling(convolve2d(pooling(convolve2d(compressed_observation, self.conv1_filtr , mode='valid')),\n",
    "                          self.conv2_filtr, mode='valid'))\n",
    "    def ForwardPropogate(self, compressed_observation):\n",
    "        result_convolution = self.Convolve(compressed_observation)\n",
    "        result_convolution = result_convolution.reshape(1, -1)\n",
    "        dense1_output = result_convolution.dot(self.dense1_weights)\n",
    "        dense1_activations = 1 / (1 + np.exp(- dense1_output))\n",
    "        dense2_output = dense1_activations.dot(self.dense2_weights)\n",
    "        dense2_activations =  1 / (1 + np.exp(- dense2_output))\n",
    "        return dense2_activations\n",
    "    def Evolution(self):\n",
    "        new_network = NeuralNetwork()\n",
    "        new_network.conv1_filtr = self.conv1_filtr +\\\n",
    "            ((np.random.standard_normal((self.conv1_size, self.conv1_size)) - self.evolution_probability) > 0) \\\n",
    "            * np.random.standard_normal((self.conv1_size, self.conv1_size)) * self.scale_factor\n",
    "        new_network.conv2_filtr = self.conv2_filtr +\\\n",
    "            ((np.random.standard_normal((self.conv2_size, self.conv2_size)) - self.evolution_probability) > 0) \\\n",
    "            * np.random.standard_normal((self.conv2_size, self.conv2_size)) * self.scale_factor\n",
    "        new_network.dense1_weights = self.dense1_weights +\\\n",
    "            ((np.random.standard_normal(self.dense1_weights.shape) - self.evolution_probability) > 0) \\\n",
    "            * np.random.standard_normal(self.dense1_weights.shape) * self.scale_factor\n",
    "        new_network.dense2_weights = self.dense2_weights +\\\n",
    "            ((np.random.standard_normal(self.dense2_weights.shape) - self.evolution_probability) > 0) \\\n",
    "            * np.random.standard_normal(self.dense2_weights.shape) * self.scale_factor\n",
    "        return new_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a = argmax_a Q(s,a)\n",
    "def predict_action(observation, network):\n",
    "    return env.action_space.sample()\n",
    "    compressed_observation = _process_frame42(observation)\n",
    "    #return np.argmax(network.ForwardPropogate(compressed_observation[:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Play one game taking actions provided by the network\n",
    "def PlayGame(env, network):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    iteration, all_reward = 0, 0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = predict_action(observation, network)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        all_reward += reward\n",
    "\n",
    "        if all_reward < -30000 or iteration >= 9000:\n",
    "            break\n",
    "        \n",
    "        iteration += 1\n",
    "\n",
    "    print(\"Reward: \", all_reward)\n",
    "    return all_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-01 17:44:38,142] Making new env: Skiing-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Skiing-v0\")\n",
    "#env = wrappers.Monitor(env, \"/tmp/gym-results\", force = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-01 17:45:00,888] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/sergei/Documents/jupyter/local/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/sergei/Documents/jupyter/local/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/sergei/Documents/jupyter/local/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1044, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1004, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 500, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/sergei/Documents/jupyter/lib/python2.7/posixpath.py\", line 382, in realpath\n",
      "    path, ok = _joinrealpath('', filename, {})\n",
      "  File \"/home/sergei/Documents/jupyter/lib/python2.7/posixpath.py\", line 406, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/home/sergei/Documents/jupyter/lib/python2.7/posixpath.py\", line 77, in join\n",
      "    elif path == '' or path.endswith('/'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/sergei/Documents/jupyter/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sergei/Documents/jupyter/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1824\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sergei/Documents/jupyter/local/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1406\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sergei/Documents/jupyter/local/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1314\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m             )\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sergei/Documents/jupyter/local/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1196\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "network = NeuralNetwork()\n",
    "print(\"Initializing...\")\n",
    "reward = PlayGame(env, network)\n",
    "print(\"Init done\")\n",
    "num_evolution_try = 3\n",
    "iteration = 0\n",
    "while reward < -6000:\n",
    "    evolution_rewards = []\n",
    "    evolution_networks = []\n",
    "    \n",
    "    for i in range(0, num_evolution_try):\n",
    "        new_network = network.Evolution()\n",
    "        evolution_networks += [new_network]\n",
    "        print(\"Epoch {1} try {2}\".format(iteration, i))\n",
    "        evolution_rewards += [PlayGame(env, new_network)]\n",
    "\n",
    "    i_max = np.argmax(evolution_rewards)\n",
    "    if evolution_rewards[i_max] < reward:\n",
    "        continue\n",
    "    else:\n",
    "        network = evolution_networks[i_max]\n",
    "        \n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PlayGame(env, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save and restore\n",
    "\n",
    "def save_to_cPickle(file_name, obj):\n",
    "    f = open(file_name + '.save', 'wb')\n",
    "    cPickle.dump(obj, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "def load_from_cPickle(file_name):\n",
    "    f = open(file_name + '.save', 'rb')\n",
    "    loaded_obj = cPickle.load(f)\n",
    "    f.close()\n",
    "    return loaded_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to_cPickle(\"best_network\", network)\n",
    "new_net = load_from_cPickle(\"best_network1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
