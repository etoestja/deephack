{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import sys, os\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "sys.path.append('/home/etoestja/peas')\n",
    "from peas.networks.rnn import NeuralNetwork\n",
    "from peas.methods.neat import NEATPopulation, NEATGenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GYMGame(object):\n",
    "    def __init__(self, game = 'Skiing-v0'):\n",
    "        self.env = gym.make(game)\n",
    "        self.actions = self.env.action_space.n\n",
    "    # Resizing to black-white 42x42\n",
    "    def resize_frame(self, frame):\n",
    "        frame = frame[34:34+160, :160]\n",
    "        # Resize by half, then down to 42x42 (essentially mipmapping). If\n",
    "        frame = cv2.resize(frame, (84, 84))\n",
    "        frame = cv2.resize(frame, (42, 42))\n",
    "        frame = cv2.resize(frame, (10, 10))\n",
    "        frame = frame.mean(2)\n",
    "        frame = frame.astype(np.float32)\n",
    "        frame *= (1.0 / 255.0)\n",
    "        return frame\n",
    "    # a = argmax_a Q(s,a)\n",
    "    def predict_action(self, observation, network):\n",
    "        #return env.action_space.sample()\n",
    "        \n",
    "        #compressed_observation = self.resize_frame(observation).flatten()\n",
    "        \n",
    "        # Dirty hack with console's RAM\n",
    "        compressed_observation = self.env._get_ram()/255.*2-1\n",
    "        s = network.feed(compressed_observation)[-self.actions:]\n",
    "        action = np.argmax(s)\n",
    "        return(action)\n",
    "    def solve(self, network):\n",
    "        return False\n",
    "    def evaluate(self, network):\n",
    "        if not isinstance(network, NeuralNetwork):\n",
    "            network = NeuralNetwork(network)\n",
    "        \n",
    "        observation = self.env.reset()\n",
    "        done = False\n",
    "        iteration, total_reward = 0, 0\n",
    "        \n",
    "        while not done:\n",
    "            #env.render()\n",
    "            action = self.predict_action(observation, network)\n",
    "            observation, reward, done, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            #if iteration % 500 == 0:\n",
    "                #print(str(iteration))\n",
    "\n",
    "            if total_reward < -12000 or iteration >= 8000:\n",
    "                break\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        \n",
    "        res = {'fitness': total_reward, 'steps': iteration}\n",
    "        #print res\n",
    "        return res\n",
    "    def genotype(self):\n",
    "        return lambda: NEATGenotype(inputs=128,\n",
    "                                outputs = self.actions,\n",
    "                                weight_range=(-3,3),\n",
    "                                types=['tanh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-06 15:00:57,179] Making new env: Skiing-v0\n"
     ]
    }
   ],
   "source": [
    "# Create game\n",
    "game = GYMGame()\n",
    "\n",
    "# Genotype of the network\n",
    "genotype = game.genotype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in 10 processes.\n"
     ]
    }
   ],
   "source": [
    "# Create a population\n",
    "pop = NEATPopulation(genotype, popsize=50, max_cores=10)\n",
    "\n",
    "# Run the evolution, tell it to use the task as an evaluator\n",
    "pop.epoch(generations=100, evaluator=game, solution=game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observation, reward, done, info = game.env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame = observation[50:50+160, 30:-30]\n",
    "frame = cv2.resize(frame, (84, 84))\n",
    "frame = cv2.resize(frame, (30, 30))\n",
    "frame = frame.mean(2)\n",
    "frame = frame.astype(np.float32)\n",
    "frame *= (1.0 / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imsave('outfile.png', frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_action_set',\n",
       " '_buffer',\n",
       " '_close',\n",
       " '_closed',\n",
       " '_configure',\n",
       " '_configured',\n",
       " '_env_closer_id',\n",
       " '_ezpickle_args',\n",
       " '_ezpickle_kwargs',\n",
       " '_get_image',\n",
       " '_get_obs',\n",
       " '_get_ram',\n",
       " '_n_actions',\n",
       " '_obs_type',\n",
       " '_owns_render',\n",
       " '_render',\n",
       " '_reset',\n",
       " '_seed',\n",
       " '_step',\n",
       " '_unwrapped',\n",
       " 'action_space',\n",
       " 'ale',\n",
       " 'close',\n",
       " 'configure',\n",
       " 'frameskip',\n",
       " 'game_path',\n",
       " 'get_action_meanings',\n",
       " 'metadata',\n",
       " 'monitor',\n",
       " 'np_random',\n",
       " 'observation_space',\n",
       " 'render',\n",
       " 'reset',\n",
       " 'reward_range',\n",
       " 'seed',\n",
       " 'spec',\n",
       " 'step',\n",
       " 'unwrapped',\n",
       " 'viewer']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(game.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.38039216, -0.89803922,  0.9372549 , -0.88235294,  0.9372549 ,\n",
       "       -0.90588235,  0.9372549 , -0.89019608,  0.9372549 , -0.92156863,\n",
       "        0.9372549 , -1.        , -1.        , -1.        ,  0.00392157,\n",
       "       -0.9372549 , -0.94509804, -1.        ,  0.00392157, -0.49803922,\n",
       "        0.00392157,  0.83529412,  0.92941176, -0.01176471,  0.9372549 ,\n",
       "       -0.40392157, -0.05882353, -1.        , -0.99215686,  0.05098039,\n",
       "       -0.78039216,  0.83529412, -0.37254902, -0.95294118, -0.59215686,\n",
       "       -0.23137255,  0.25490196,  0.74117647,  0.00392157, -1.        ,\n",
       "       -0.98431373,  0.04313725,  0.04313725, -0.96862745, -0.98431373,\n",
       "        0.02745098, -0.01176471,  0.23137255, -0.12941176, -0.01176471,\n",
       "       -0.01176471,  0.23137255, -0.12941176, -0.01176471,  1.        ,\n",
       "        1.        ,  1.        ,  1.        , -0.75686275, -0.94509804,\n",
       "       -0.88235294, -0.75686275, -0.38039216, -0.94509804, -0.76470588,\n",
       "        0.21568627,  0.19215686, -0.5372549 , -0.67843137,  0.00392157,\n",
       "       -0.33333333, -0.96078431, -0.98431373, -0.33333333, -0.33333333,\n",
       "       -0.96078431, -0.98431373, -0.33333333, -0.95294118, -0.96078431,\n",
       "       -1.        , -0.97647059, -0.98431373, -0.99215686, -1.        ,\n",
       "       -0.94509804,  0.52941176,  0.38039216,  0.67843137,  0.25490196,\n",
       "       -0.37254902, -0.68627451, -0.81176471, -0.96862745, -0.96862745,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -0.74901961,  0.33333333,  1.        ,\n",
       "       -1.        ,  1.        ,  0.30980392,  0.68627451, -0.33333333,\n",
       "        0.0745098 , -1.        , -1.        , -0.74901961, -0.99215686,\n",
       "       -0.50588235, -1.        ,  0.88235294, -0.43529412, -0.89019608,\n",
       "        0.91372549, -0.65490196,  0.89019608])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.env._get_ram()/255.*2-1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
