{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skiing by evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skiing game has a reward which is more difficult in terms of learning.\n",
    "\n",
    "The goal of the game is to avoid trees and pass through the gates, but the reward is given only at the end. Reward equals to -3..-7 for living and -500 * (missed gates) at the end.\n",
    "\n",
    "Because of that, the agent can evaluate its behavior only at the end of the game, and not immediately after passing (or not passing) gates.\n",
    "\n",
    "The standart Q-learning technique would require significant amount of training in this case, because 99.9% of the network's weight updates would be meaningless, as they correspond to that random living penalty.\n",
    "\n",
    "Therefore, we use another approach to train the network: an evolutionary algorithm. We use mutation and selection based on sum of rewards to train the network, instead of gradient updates. The solution basically follows this scheme:\n",
    "1. Create random set of NN's, each consisting of 2 convolutional and 2 fully-connected layers\n",
    "2. Evaluate their fitness (i.e. sum of rewards)\n",
    "3. Choose the best ones\n",
    "4. Crossover and mutate them (possibly adding new neurons)\n",
    "5. Repeat stage 2 for the result.\n",
    "\n",
    "Our solution is inspired by a method called NEAT, used to play Mario: https://www.youtube.com/watch?v=qv6UVOQ0F44\n",
    "\n",
    "The example on the video uses handcrafted features, but we use 2 convolutional layers trained the same way instead. This way, this approach (theoretically) can play any game of this kind, without any game-specific features or rewards\n",
    "\n",
    "However, training was not enough, so now it is able only of going straight down (at the beginning it presses keys quite randomly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "почему 5x5?\n",
    "\n",
    "1. http://cs231n.github.io/convolutional-networks/\n",
    "2. https://code.google.com/p/cuda-convnet/wiki/LayerParams#Local_response_normalization_layer_(same_map)\n",
    "3. https://github.com/BVLC/caffe/blob/master/examples/net_surgery.ipynb\n",
    "4. https://arxiv.org/abs/1602.07261\n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, cuDNN 5105)\n",
      "/home/etoestja/venv/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from six.moves import cPickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "import theano\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resizing to black-white 42x42\n",
    "def _process_frame42(frame):\n",
    "    frame = frame[34:34+160, :160]\n",
    "    # Resize by half, then down to 42x42 (essentially mipmapping). If\n",
    "    # we resize directly we lose pixels that, when mapped to 42x42,\n",
    "    # aren't close enough to the pixel boundary.\n",
    "    frame = cv2.resize(frame, (80, 80))\n",
    "    frame = cv2.resize(frame, (42, 42))\n",
    "    frame = frame.mean(2)\n",
    "    frame = frame.astype(np.float32)\n",
    "    frame *= (1.0 / 255.0)\n",
    "    frame = np.reshape(frame, [42, 42, 1])\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neural Evolution\n",
    "class NeuralNetwork:\n",
    "    conv1_size = 5\n",
    "    conv2_size = 5\n",
    "    evolution_probability = 0.97\n",
    "    scale_factor = 1\n",
    "    def __init__(self):\n",
    "        self.conv1_filtr = np.random.standard_normal((self.conv1_size, self.conv1_size))\n",
    "        self.conv2_filtr = np.random.standard_normal((self.conv2_size, self.conv2_size))\n",
    "        self.dense1_weights = np.random.standard_normal((49, 100))\n",
    "        self.dense2_weights = np.random.standard_normal((100, 3))\n",
    "    def Convolve(self, compressed_observation):\n",
    "        input_var = T.dmatrix('inputs')\n",
    "\n",
    "        pooling = theano.function([input_var],\n",
    "                                  theano.tensor.signal.pool.pool_2d(input_var, (2, 2), ignore_border=True))\n",
    "        return pooling(convolve2d(pooling(convolve2d(compressed_observation, self.conv1_filtr , mode='valid')),\n",
    "                          self.conv2_filtr, mode='valid'))\n",
    "    def ForwardPropogate(self, compressed_observation):\n",
    "        result_convolution = self.Convolve(compressed_observation)\n",
    "        result_convolution = result_convolution.reshape(1, -1)\n",
    "        dense1_output = result_convolution.dot(self.dense1_weights)\n",
    "        dense1_activations = 1 / (1 + np.exp(- dense1_output))\n",
    "        dense2_output = dense1_activations.dot(self.dense2_weights)\n",
    "        dense2_activations =  1 / (1 + np.exp(- dense2_output))\n",
    "        return dense2_activations\n",
    "    def Evolution(self):\n",
    "        new_network = NeuralNetwork()\n",
    "        new_network.conv1_filtr = self.conv1_filtr +\\\n",
    "            ((np.random.standard_normal((self.conv1_size, self.conv1_size)) - self.evolution_probability) > 0) \\\n",
    "            * np.random.standard_normal((self.conv1_size, self.conv1_size)) * self.scale_factor\n",
    "        new_network.conv2_filtr = self.conv2_filtr +\\\n",
    "            ((np.random.standard_normal((self.conv2_size, self.conv2_size)) - self.evolution_probability) > 0) \\\n",
    "            * np.random.standard_normal((self.conv2_size, self.conv2_size)) * self.scale_factor\n",
    "        new_network.dense1_weights = self.dense1_weights +\\\n",
    "            ((np.random.standard_normal(self.dense1_weights.shape) - self.evolution_probability) > 0) \\\n",
    "            * np.random.standard_normal(self.dense1_weights.shape) * self.scale_factor\n",
    "        new_network.dense2_weights = self.dense2_weights +\\\n",
    "            ((np.random.standard_normal(self.dense2_weights.shape) - self.evolution_probability) > 0) \\\n",
    "            * np.random.standard_normal(self.dense2_weights.shape) * self.scale_factor\n",
    "        return new_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a = argmax_a Q(s,a)\n",
    "def predict_action(observation, network):\n",
    "    #return env.action_space.sample()\n",
    "    compressed_observation = _process_frame42(observation)\n",
    "    return np.argmax(network.ForwardPropogate(compressed_observation[:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Play one game taking actions provided by the network\n",
    "def PlayGame(env, network):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    iteration, all_reward = 0, 0\n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = predict_action(observation, network)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        all_reward += reward\n",
    "\n",
    "        #if iteration % 500 == 0:\n",
    "        print(str(iteration) + \"... \")\n",
    "        \n",
    "        if all_reward < -30000 or iteration >= 8000:\n",
    "            break\n",
    "        \n",
    "        iteration += 1\n",
    "\n",
    "    print(\"Reward: \", all_reward)\n",
    "    return all_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-06 11:52:36,971] Making new env: Skiing-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Skiing-v0\")\n",
    "#env = wrappers.Monitor(env, \"/tmp/gym-results\", force = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "0... \n",
      "1... \n",
      "2... \n",
      "3... \n",
      "4... \n",
      "5... \n",
      "6... \n",
      "7... \n",
      "8... \n",
      "9... \n",
      "10... \n",
      "11... \n",
      "12... \n",
      "13... \n",
      "14... \n",
      "15... \n",
      "16... \n",
      "17... \n",
      "18... \n",
      "19... \n",
      "20... \n",
      "21... \n",
      "22... \n",
      "23... \n",
      "24... \n",
      "25... \n",
      "26... \n",
      "27... \n",
      "28... \n",
      "29... \n",
      "30... \n",
      "31... \n",
      "32... \n",
      "33... \n",
      "34... \n",
      "35... \n",
      "36... \n",
      "37... \n",
      "38... \n",
      "39... \n",
      "40... \n",
      "41... \n",
      "42... \n",
      "43... \n",
      "44... \n",
      "45... \n",
      "46... \n",
      "47... \n",
      "48... \n",
      "49... \n",
      "50... \n",
      "51... \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 1118, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 300, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1044, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1008, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 172, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/usr/lib/python2.7/linecache.py\", line 40, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/usr/lib/python2.7/linecache.py\", line 128, in updatecache\n",
      "    lines = fp.readlines()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[0;32m   1828\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 1830\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   1831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1390\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1392\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1298\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1300\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1301\u001b[0m             )\n\u001b[0;32m   1302\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-06 11:53:07,085] Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 413, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 626, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 649, in _abort_queue\n",
      "    poller.poll(50)\n",
      "  File \"/usr/lib/python2.7/dist-packages/zmq/sugar/poll.py\", line 101, in poll\n",
      "    return zmq_poll(self.sockets, timeout=timeout)\n",
      "  File \"zmq/backend/cython/_poll.pyx\", line 115, in zmq.backend.cython._poll.zmq_poll (zmq/backend/cython/_poll.c:1586)\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 11, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/_poll.c:1790)\n",
      "    PyErr_CheckSignals()\n",
      "KeyboardInterrupt\n",
      "[2017-02-06 11:53:07,091] Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 413, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 626, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 649, in _abort_queue\n",
      "    poller.poll(50)\n",
      "  File \"/usr/lib/python2.7/dist-packages/zmq/sugar/poll.py\", line 101, in poll\n",
      "    return zmq_poll(self.sockets, timeout=timeout)\n",
      "  File \"zmq/backend/cython/_poll.pyx\", line 115, in zmq.backend.cython._poll.zmq_poll (zmq/backend/cython/_poll.c:1586)\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 11, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/_poll.c:1790)\n",
      "    PyErr_CheckSignals()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "network = NeuralNetwork()\n",
    "print(\"Initializing...\")\n",
    "reward = PlayGame(env, network)\n",
    "print(\"Init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 try 0\n",
      "0... \n",
      "500... \n",
      "('Reward: ', -9013.0)\n",
      "Epoch 0 try 1\n",
      "0... \n",
      "500... \n",
      "1000... \n",
      "1500... \n",
      "2000... \n",
      "2500... \n",
      "3000... \n",
      "3500... \n",
      "4000... \n",
      "4500... \n",
      "5000... \n",
      "5500... \n",
      "6000... \n",
      "('Reward: ', -30000.0)\n",
      "Epoch 0 try 2\n",
      "0... \n",
      "500... \n",
      "('Reward: ', -9013.0)\n",
      "Epoch 1 try 0\n",
      "0... \n",
      "500... \n",
      "1000... \n",
      "1500... \n",
      "2000... \n",
      "2500... \n",
      "3000... \n",
      "3500... \n",
      "4000... \n",
      "4500... \n",
      "5000... \n",
      "5500... \n",
      "6000... \n",
      "('Reward: ', -30000.0)\n",
      "Epoch 1 try 1\n",
      "0... \n",
      "500... \n",
      "1000... \n",
      "1500... \n",
      "2000... \n",
      "2500... \n",
      "3000... \n",
      "3500... \n",
      "4000... \n",
      "4500... \n",
      "5000... \n",
      "5500... \n",
      "6000... \n",
      "('Reward: ', -30000.0)\n",
      "Epoch 1 try 2\n",
      "0... \n",
      "500... \n",
      "('Reward: ', -9013.0)\n",
      "Epoch 2 try 0\n",
      "0... \n",
      "500... \n",
      "1000... \n",
      "1500... \n",
      "2000... \n",
      "2500... \n",
      "3000... \n",
      "3500... \n"
     ]
    }
   ],
   "source": [
    "num_evolution_try = 3\n",
    "iteration = 0\n",
    "while reward < -6000:\n",
    "    evolution_rewards = []\n",
    "    evolution_networks = []\n",
    "    \n",
    "    for i in range(0, num_evolution_try):\n",
    "        new_network = network.Evolution()\n",
    "        evolution_networks += [new_network]\n",
    "        print(\"Epoch {0} try {1}\".format(iteration, i))\n",
    "        evolution_rewards += [PlayGame(env, new_network)]\n",
    "\n",
    "    i_max = np.argmax(evolution_rewards)\n",
    "    if evolution_rewards[i_max] < reward:\n",
    "        continue\n",
    "    else:\n",
    "        network = evolution_networks[i_max]\n",
    "        \n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PlayGame(env, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save and restore\n",
    "\n",
    "def save_to_cPickle(file_name, obj):\n",
    "    f = open(file_name + '.save', 'wb')\n",
    "    cPickle.dump(obj, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "def load_from_cPickle(file_name):\n",
    "    f = open(file_name + '.save', 'rb')\n",
    "    loaded_obj = cPickle.load(f)\n",
    "    f.close()\n",
    "    return loaded_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to_cPickle(\"best_network\", network)\n",
    "new_net = load_from_cPickle(\"best_network1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
